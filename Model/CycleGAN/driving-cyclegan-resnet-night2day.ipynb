{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":442057,"sourceType":"datasetVersion","datasetId":161598}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# https://keras.io/examples/generative/cyclegan/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import tf_keras as keras\nimport keras\nimport os\n#os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras import layers\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tf.keras.layers.GroupNormalization(groups=-1)\n#https://www.tensorflow.org/api_docs/python/tf/keras/layers/GroupNormalization\n#Relation to Instance Normalization: If the number of groups is set to the input dimension (number of groups is equal to number of channels), then this operation becomes identical to Instance Normalization. You can achieve this via groups=-1.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_path = '/kaggle/input/solesensei_bdd100k/bdd100k/bdd100k/images/100k'\n\ntrainA_path = os.path.join(dataset_path, 'train/trainA')\ntrainB_path = os.path.join(dataset_path, 'train/trainB')\n\ntestA_path = os.path.join(dataset_path, 'train/testA')\ntestB_path = os.path.join(dataset_path, 'train/testB')\n\nBUFFER_SIZE = 256\nbatch_size = 1\nimg_size = (256, 256)\norig_img_size = (720, 720)\ninput_img_size = (256, 256, 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import shutil\n#if os.path.exists('/kaggle/working/Model'):\n#    shutil.rmtree('/kaggle/working/Model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_img_dir = '/kaggle/working/Model/Model_Data/save'\noutput_ckpt_dir = '/kaggle/working/Model/Model_Data/ckpt'\nbackup_dir = '/kaggle/working/Model/Model_Data/backup'\n\nfor i in (output_img_dir, output_ckpt_dir, backup_dir):\n    if not os.path.exists(i):\n        os.makedirs(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A -> Day\n# B -> Night","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train_day = glob.glob(os.path.join(dataset_path, 'train/trainA/*.jpg'))\ntrain_night = glob.glob(os.path.join(dataset_path, 'train/trainB/*.jpg'))\n\nprint(len(train_day), len(train_night))","metadata":{"execution":{"iopub.status.busy":"2024-10-22T17:39:17.785299Z","iopub.execute_input":"2024-10-22T17:39:17.785785Z","iopub.status.idle":"2024-10-22T17:39:18.044880Z","shell.execute_reply.started":"2024-10-22T17:39:17.785742Z","shell.execute_reply":"2024-10-22T17:39:18.043603Z"}}},{"cell_type":"markdown","source":"val_day = glob.glob(os.path.join(dataset_path, 'train/testA/*.jpg'))\nval_night = glob.glob(os.path.join(dataset_path, 'train/testB/*.jpg'))\n\nprint(len(val_day), len(val_night))","metadata":{"execution":{"iopub.status.busy":"2024-10-22T17:39:18.046813Z","iopub.execute_input":"2024-10-22T17:39:18.047913Z","iopub.status.idle":"2024-10-22T17:39:18.086223Z","shell.execute_reply.started":"2024-10-22T17:39:18.047851Z","shell.execute_reply":"2024-10-22T17:39:18.084930Z"}}},{"cell_type":"markdown","source":"train_day = train_day[::17]\ntrain_night = train_night[::13]\nprint(len(train_day),len(train_night))","metadata":{"execution":{"iopub.status.busy":"2024-10-22T17:39:18.087770Z","iopub.execute_input":"2024-10-22T17:39:18.088176Z","iopub.status.idle":"2024-10-22T17:39:18.096422Z","shell.execute_reply.started":"2024-10-22T17:39:18.088135Z","shell.execute_reply":"2024-10-22T17:39:18.095162Z"}}},{"cell_type":"markdown","source":"val_day = val_day[::10]\nval_night = val_night[::6]\nprint(len(val_day),len(val_night))","metadata":{"execution":{"iopub.status.busy":"2024-10-22T17:39:18.097846Z","iopub.execute_input":"2024-10-22T17:39:18.098278Z","iopub.status.idle":"2024-10-22T17:39:18.110582Z","shell.execute_reply.started":"2024-10-22T17:39:18.098236Z","shell.execute_reply":"2024-10-22T17:39:18.109280Z"}}},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"trainB = tf.data.Dataset.list_files(os.path.join(dataset_path, 'test/trainA/*jpg'), shuffle=True).take(1200)\ntrainA = tf.data.Dataset.list_files(os.path.join(dataset_path, 'test/trainB/*jpg'), shuffle=True).take(1200)\n\ntestB = tf.data.Dataset.list_files(os.path.join(dataset_path, 'test/testA/*jpg'), shuffle=True).take(400)\ntestA = tf.data.Dataset.list_files(os.path.join(dataset_path, 'test/testB/*jpg'), shuffle=True).take(400)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kernel_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\ngamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load(image_file):\n    image = tf.io.read_file(image_file)\n    image = tf.io.decode_jpeg(image, channels=3)\n\n    return image\n\n\ndef normalize_img(img):\n    img = tf.cast(img, dtype=tf.float32)\n    return (img / 127.5) - 1.0\n\n\ndef preprocess_train_image(img):\n    img = tf.image.random_flip_left_right(img)\n    img = tf.image.resize(img, [*orig_img_size])\n    img = tf.image.random_crop(img, size=[*img_size, 3])\n    img = normalize_img(img)\n    return img\n\n\ndef preprocess_test_image(img):\n    img = tf.image.resize(img, [img_size[0], img_size[1]])\n    img = normalize_img(img)\n    return img\n\ndef map_train_load(image):\n    image = load(image)\n    image = preprocess_train_image(image)\n    return image\n\ndef map_test_load(image):\n    image = load(image)\n    image = preprocess_test_image(image)\n    return image\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainA = (\n    trainA.map(map_train_load, num_parallel_calls=AUTOTUNE)\n    .cache()\n    .shuffle(BUFFER_SIZE)\n    .batch(batch_size)\n)\ntrainB = (\n    trainB.map(map_train_load, num_parallel_calls=AUTOTUNE)\n    .cache()\n    .shuffle(BUFFER_SIZE)\n    .batch(batch_size)\n)\n\ntestA = (\n    testA.map(map_test_load, num_parallel_calls=AUTOTUNE)\n    .cache()\n    .shuffle(BUFFER_SIZE)\n    .batch(batch_size)\n)\ntestB = (\n    testB.map(map_test_load, num_parallel_calls=AUTOTUNE)\n    .cache()\n    .shuffle(BUFFER_SIZE)\n    .batch(batch_size)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def read_jpg(path):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    return img\n\ndef normalize(input_image):\n    input_image = tf.cast(input_image, tf.float32)/127.5 - 1\n    return input_image\n\ndef load_image(image_path):\n    image = read_jpg(image_path)\n    image = tf.image.resize(image, (256, 256))\n    image = normalize(image)\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-10-22T17:39:18.112118Z","iopub.execute_input":"2024-10-22T17:39:18.112510Z","iopub.status.idle":"2024-10-22T17:39:18.122418Z","shell.execute_reply.started":"2024-10-22T17:39:18.112468Z","shell.execute_reply":"2024-10-22T17:39:18.121171Z"}}},{"cell_type":"code","source":"_, ax = plt.subplots(2, 2, figsize=(15, 15))\nfor i, samples in enumerate(zip(trainA.take(2), trainB.take(2))):\n    day = (((samples[0][0] * 127.5) + 127.5).numpy()).astype(np.uint8)\n    night = (((samples[1][0] * 127.5) + 127.5).numpy()).astype(np.uint8)\n    ax[i, 0].imshow(day)\n    ax[i, 1].imshow(night)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"class ReflectionPadding2D(layers.Layer):\n    def __init__(self, padding=(1, 1), **kwargs):\n        self.padding = tuple(padding)\n        super().__init__(**kwargs)\n\n    def call(self, input_tensor, mask=None):\n        padding_width, padding_height = self.padding\n        padding_tensor = [\n            [0, 0],\n            [padding_height, padding_height],\n            [padding_width, padding_width],\n            [0, 0],\n        ]\n        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def residual_block(\n    x,\n    activation,\n    kernel_initializer=kernel_init,\n    kernel_size=(3, 3),\n    strides=(1, 1),\n    padding=\"valid\",\n    gamma_initializer=gamma_init,\n    use_bias=False,\n):\n    dim = x.shape[-1]\n    input_tensor = x\n\n    x = ReflectionPadding2D()(input_tensor)\n    x = layers.Conv2D(\n        dim,\n        kernel_size,\n        strides=strides,\n        kernel_initializer=kernel_initializer,\n        padding=padding,\n        use_bias=use_bias,\n    )(x)\n    x = tf.keras.layers.GroupNormalization(groups=-1, gamma_initializer=gamma_initializer)(x)\n    x = activation(x)\n\n    x = ReflectionPadding2D()(x)\n    x = layers.Conv2D(\n        dim,\n        kernel_size,\n        strides=strides,\n        kernel_initializer=kernel_initializer,\n        padding=padding,\n        use_bias=use_bias,\n    )(x)\n    x = tf.keras.layers.GroupNormalization(groups=-1, gamma_initializer=gamma_initializer)(x)\n    x = layers.add([input_tensor, x])\n    return x\n\n\ndef downsample(\n    x,\n    filters,\n    activation,\n    kernel_initializer=kernel_init,\n    kernel_size=(3, 3),\n    strides=(2, 2),\n    padding=\"same\",\n    gamma_initializer=gamma_init,\n    use_bias=False,\n):\n    x = layers.Conv2D(\n        filters,\n        kernel_size,\n        strides=strides,\n        kernel_initializer=kernel_initializer,\n        padding=padding,\n        use_bias=use_bias,\n    )(x)\n    x = tf.keras.layers.GroupNormalization(groups=-1, gamma_initializer=gamma_initializer)(x)\n    if activation:\n        x = activation(x)\n    return x\n\n\ndef upsample(\n    x,\n    filters,\n    activation,\n    kernel_size=(3, 3),\n    strides=(2, 2),\n    padding=\"same\",\n    kernel_initializer=kernel_init,\n    gamma_initializer=gamma_init,\n    use_bias=False,\n):\n    x = layers.Conv2DTranspose(\n        filters,\n        kernel_size,\n        strides=strides,\n        padding=padding,\n        kernel_initializer=kernel_initializer,\n        use_bias=use_bias,\n    )(x)\n    x = tf.keras.layers.GroupNormalization(groups=-1, gamma_initializer=gamma_initializer)(x)\n    if activation:\n        x = activation(x)\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_resnet_generator(\n    filters=64,\n    num_downsampling_blocks=2,\n    num_residual_blocks=9,\n    num_upsample_blocks=2,\n    gamma_initializer=gamma_init,\n    name=None,\n):\n    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n    x = ReflectionPadding2D(padding=(3, 3))(img_input)\n    x = layers.Conv2D(filters, (7, 7), kernel_initializer=kernel_init, use_bias=False)(\n        x\n    )\n    x = tf.keras.layers.GroupNormalization(groups=-1, gamma_initializer=gamma_initializer)(x)\n    x = layers.Activation(\"relu\")(x)\n\n    # Downsampling\n    for _ in range(num_downsampling_blocks):\n        filters *= 2\n        x = downsample(x, filters=filters, activation=layers.Activation(\"relu\"))\n\n    # Residual blocks\n    for _ in range(num_residual_blocks):\n        x = residual_block(x, activation=layers.Activation(\"relu\"))\n\n    # Upsampling\n    for _ in range(num_upsample_blocks):\n        filters //= 2\n        x = upsample(x, filters, activation=layers.Activation(\"relu\"))\n\n    # Final block\n    x = ReflectionPadding2D(padding=(3, 3))(x)\n    x = layers.Conv2D(3, (7, 7), padding=\"valid\")(x)\n    x = layers.Activation(\"tanh\")(x)\n\n    model = tf.keras.models.Model(img_input, x, name=name)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_discriminator(\n    filters=64, kernel_initializer=kernel_init, num_downsampling=3, name=None\n):\n    img_input = layers.Input(shape=input_img_size, name=name + \"_img_input\")\n    x = layers.Conv2D(\n        filters,\n        (4, 4),\n        strides=(2, 2),\n        padding=\"same\",\n        kernel_initializer=kernel_initializer,\n    )(img_input)\n    x = layers.LeakyReLU(0.2)(x)\n\n    num_filters = filters\n    for num_downsample_block in range(3):\n        num_filters *= 2\n        if num_downsample_block < 2:\n            x = downsample(\n                x,\n                filters=num_filters,\n                activation=layers.LeakyReLU(0.2),\n                kernel_size=(4, 4),\n                strides=(2, 2),\n            )\n        else:\n            x = downsample(\n                x,\n                filters=num_filters,\n                activation=layers.LeakyReLU(0.2),\n                kernel_size=(4, 4),\n                strides=(1, 1),\n            )\n\n    x = layers.Conv2D(\n        1, (4, 4), strides=(1, 1), padding=\"same\", kernel_initializer=kernel_initializer\n    )(x)\n\n    model = tf.keras.models.Model(inputs=img_input, outputs=x, name=name)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_G = get_resnet_generator(name=\"generator_G\")\ngen_F = get_resnet_generator(name=\"generator_F\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disc_X = get_discriminator(name=\"discriminator_X\")\ndisc_Y = get_discriminator(name=\"discriminator_Y\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class CycleGan(tf.keras.Model):\n    def __init__(\n        self,\n        generator_G,\n        generator_F,\n        discriminator_X,\n        discriminator_Y,\n        lambda_cycle=10.0,\n        lambda_identity=0.5,\n    ):\n        super().__init__()\n        self.gen_G = generator_G\n        self.gen_F = generator_F\n        self.disc_X = discriminator_X\n        self.disc_Y = discriminator_Y\n        self.lambda_cycle = lambda_cycle\n        self.lambda_identity = lambda_identity\n\n    def compile(\n        self,\n        gen_G_optimizer,\n        gen_F_optimizer,\n        disc_X_optimizer,\n        disc_Y_optimizer,\n        gen_loss_fn,\n        disc_loss_fn,\n    ):\n        super().compile()\n        self.gen_G_optimizer = gen_G_optimizer\n        self.gen_F_optimizer = gen_F_optimizer\n        self.disc_X_optimizer = disc_X_optimizer\n        self.disc_Y_optimizer = disc_Y_optimizer\n        self.generator_loss_fn = gen_loss_fn\n        self.discriminator_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = keras.losses.MeanAbsoluteError()\n        self.identity_loss_fn = keras.losses.MeanAbsoluteError()\n\n    def train_step(self, batch_data):\n        # x is Day and y is Night\n        real_x, real_y = batch_data\n\n        # For CycleGAN, we need to calculate different\n        # kinds of losses for the generators and discriminators.\n        # We will perform the following steps here:\n        #\n        # 1. Pass real images through the generators and get the generated images\n        # 2. Pass the generated images back to the generators to check if we\n        #    can predict the original image from the generated image.\n        # 3. Do an identity mapping of the real images using the generators.\n        # 4. Pass the generated images in 1) to the corresponding discriminators.\n        # 5. Calculate the generators total loss (adversarial + cycle + identity)\n        # 6. Calculate the discriminators loss\n        # 7. Update the weights of the generators\n        # 8. Update the weights of the discriminators\n        # 9. Return the losses in a dictionary\n\n        with tf.GradientTape(persistent=True) as tape:\n            # Day to fake night\n            fake_y = self.gen_G(real_x, training=True)\n            # Night to fake day -> y2x\n            fake_x = self.gen_F(real_y, training=True)\n\n            # Cycle (Day to fake night to fake day): x -> y -> x\n            cycled_x = self.gen_F(fake_y, training=True)\n            # Cycle (Night to fake day to fake night) y -> x -> y\n            cycled_y = self.gen_G(fake_x, training=True)\n\n            # Identity mapping\n            same_x = self.gen_F(real_x, training=True)\n            same_y = self.gen_G(real_y, training=True)\n\n            # Discriminator output\n            disc_real_x = self.disc_X(real_x, training=True)\n            disc_fake_x = self.disc_X(fake_x, training=True)\n\n            disc_real_y = self.disc_Y(real_y, training=True)\n            disc_fake_y = self.disc_Y(fake_y, training=True)\n\n            # Generator adversarial loss\n            gen_G_loss = self.generator_loss_fn(disc_fake_y)\n            gen_F_loss = self.generator_loss_fn(disc_fake_x)\n\n            # Generator cycle loss\n            cycle_loss_G = self.cycle_loss_fn(real_y, cycled_y) * self.lambda_cycle\n            cycle_loss_F = self.cycle_loss_fn(real_x, cycled_x) * self.lambda_cycle\n\n            # Generator identity loss\n            id_loss_G = (\n                self.identity_loss_fn(real_y, same_y)\n                * self.lambda_cycle\n                * self.lambda_identity\n            )\n            id_loss_F = (\n                self.identity_loss_fn(real_x, same_x)\n                * self.lambda_cycle\n                * self.lambda_identity\n            )\n\n            # Total generator loss\n            total_loss_G = gen_G_loss + cycle_loss_G + id_loss_G\n            total_loss_F = gen_F_loss + cycle_loss_F + id_loss_F\n\n            # Discriminator loss\n            disc_X_loss = self.discriminator_loss_fn(disc_real_x, disc_fake_x)\n            disc_Y_loss = self.discriminator_loss_fn(disc_real_y, disc_fake_y)\n\n        # Get the gradients for the generators\n        grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)\n        grads_F = tape.gradient(total_loss_F, self.gen_F.trainable_variables)\n\n        # Get the gradients for the discriminators\n        disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)\n        disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)\n\n        # Update the weights of the generators\n        self.gen_G_optimizer.apply_gradients(\n            zip(grads_G, self.gen_G.trainable_variables)\n        )\n        self.gen_F_optimizer.apply_gradients(\n            zip(grads_F, self.gen_F.trainable_variables)\n        )\n\n        # Update the weights of the discriminators\n        self.disc_X_optimizer.apply_gradients(\n            zip(disc_X_grads, self.disc_X.trainable_variables)\n        )\n        self.disc_Y_optimizer.apply_gradients(\n            zip(disc_Y_grads, self.disc_Y.trainable_variables)\n        )\n\n        return {\n            \"G_loss\": total_loss_G,\n            \"F_loss\": total_loss_F,\n            \"D_X_loss\": disc_X_loss,\n            \"D_Y_loss\": disc_Y_loss,\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Callback","metadata":{}},{"cell_type":"code","source":"class GANMonitor(tf.keras.callbacks.Callback):\n    def __init__(self, num_img=2):\n        self.num_img = num_img\n\n    def on_epoch_end(self, epoch, logs=None):\n        _, ax = plt.subplots(2, 2, figsize=(12, 12))\n        for i, img in enumerate(testA.take(self.num_img)):\n            prediction = self.model.gen_G(img, training=False)[0].numpy()\n            prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n            img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n            ax[i, 0].imshow(img)\n            ax[i, 1].imshow(prediction)\n            ax[i, 0].set_title(\"Input image\")\n            ax[i, 1].set_title(\"Translated image\")\n            ax[i, 0].axis(\"off\")\n            ax[i, 1].axis(\"off\")\n\n            prediction = tf.keras.utils.array_to_img(prediction)\n            prediction.save(\n                f\"{output_img_dir}/generated_img_{i}_{epoch+1}.png\"\n            )\n        plt.show()\n        plt.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotter = GANMonitor()\ncheckpoint_filepath = output_ckpt_dir + \"/cyclegan_checkpoints.{epoch:03d}.weights.h5\"\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath, save_weights_only=True\n)\nbackup_callback = keras.callbacks.BackupAndRestore(backup_dir=backup_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"adv_loss_fn = tf.keras.losses.MeanSquaredError()\n\ndef generator_loss_fn(fake):\n    fake_loss = adv_loss_fn(tf.ones_like(fake), fake)\n    return fake_loss\n\n\ndef discriminator_loss_fn(real, fake):\n    real_loss = adv_loss_fn(tf.ones_like(real), real)\n    fake_loss = adv_loss_fn(tf.zeros_like(fake), fake)\n    return (real_loss + fake_loss) * 0.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cycle_gan_model = CycleGan(\n    generator_G=gen_G, generator_F=gen_F, discriminator_X=disc_X, discriminator_Y=disc_Y\n)\n\ncycle_gan_model.compile(\n    gen_G_optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    gen_F_optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    disc_X_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    disc_Y_optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    gen_loss_fn=generator_loss_fn,\n    disc_loss_fn=discriminator_loss_fn,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cycle_gan_model.build((1, 256, 256, 3))\n\ncycle_gan_model.gen_G.build((1, 256, 256, 3))\ncycle_gan_model.gen_F.build((1, 256, 256, 3))\ncycle_gan_model.disc_X.build((1, 256, 256, 3))\ncycle_gan_model.disc_Y.build((1, 256, 256, 3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = cycle_gan_model.fit(\n    tf.data.Dataset.zip((trainA, trainB)),\n    epochs=100,\n    callbacks=[plotter, model_checkpoint_callback, backup_callback]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}